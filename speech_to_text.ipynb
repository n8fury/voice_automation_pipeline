{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "from IPython.display import Audio\n",
    "from scipy.io import wavfile\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import speech_recognition as sr\n",
    "from gtts import gTTS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHUNK = 1024\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 1\n",
    "RATE = 44100\n",
    "RECORD_SECONDS = 5\n",
    "p = pyaudio.PyAudio()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "V1_using_Pyaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting recording first.wav.\n",
      "finished recording\n"
     ]
    }
   ],
   "source": [
    "def record(file_name):\n",
    "\n",
    "  stream = p.open(format=FORMAT,\n",
    "                  channels=CHANNELS,\n",
    "                  rate=RATE,\n",
    "                  input=True,\n",
    "                  frames_per_buffer=CHUNK)\n",
    "\n",
    "  frames = []\n",
    "  print (\"starting recording \" + file_name + \".\")\n",
    "  for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "    data = stream.read(CHUNK)\n",
    "    frames.append(data)\n",
    "  print (\"finished recording\")\n",
    "\n",
    "  stream.stop_stream()\n",
    "  stream.close()\n",
    "  p.terminate()\n",
    "\n",
    "  wf = wave.open(file_name, 'wb')\n",
    "  wf.setnchannels(CHANNELS)\n",
    "  wf.setsampwidth(p.get_sample_size(FORMAT))\n",
    "  wf.setframerate(RATE)\n",
    "  wf.writeframes(b''.join(frames))\n",
    "  wf.close()\n",
    "\n",
    "\n",
    "record('first.wav')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileName = 'first.wav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample rate: 44100 Hz\n",
      "Total time: 9.984580498866213 s\n"
     ]
    }
   ],
   "source": [
    "data = wavfile.read(fileName)\n",
    "framerate = data[0]\n",
    "sounddata = data[1]\n",
    "time = np.arange(0, len(sounddata))/framerate\n",
    "print('Sample rate:', framerate, 'Hz')\n",
    "print('Total time:', len(sounddata)/framerate, 's')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa  # for managing the audio file\n",
    "import torch\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'Wav2Vec2CTCTokenizer'. \n",
      "The class this function is called from is 'Wav2Vec2Tokenizer'.\n",
      "C:\\Users\\mhjoy\\anaconda3\\lib\\site-packages\\transformers\\models\\wav2vec2\\tokenization_wav2vec2.py:746: FutureWarning: The class `Wav2Vec2Tokenizer` is deprecated and will be removed in version 5 of Transformers. Please use `Wav2Vec2Processor` or `Wav2Vec2CTCTokenizer` instead.\n",
      "  warnings.warn(\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Wav2Vec2Tokenizer.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base-960h\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech,rate = librosa.load('first.wav', sr=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_values = tokenizer(speech, return_tensors=\"pt\").input_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0484, -0.0996, -0.0685,  ...,  0.0239, -0.1330,  0.0010]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 14.0742, -25.9040, -25.5672,  ...,  -6.3550,  -6.8113,  -6.1068],\n",
       "         [ 14.0969, -25.8749, -25.5359,  ...,  -6.4096,  -6.7946,  -6.1242],\n",
       "         [ 14.3617, -25.9920, -25.6600,  ...,  -6.3898,  -6.7857,  -6.0866],\n",
       "         ...,\n",
       "         [  6.0922, -22.8101, -22.8351,  ...,  -7.8232,  -8.4150,  -5.0796],\n",
       "         [  5.5397, -20.0114, -20.0653,  ...,  -6.3704,  -6.6621,  -4.4444],\n",
       "         [  5.5728, -19.6715, -19.6251,  ...,  -5.5756,  -5.8843,  -2.9330]]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = model(input_values).logits\n",
    "logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_ids = torch.argmax(logits, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcriptions = tokenizer.decode(predicted_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THIS IS VOIAS AUTOMITION SAID SOMEON DO\n"
     ]
    }
   ],
   "source": [
    "print(transcriptions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FINISHED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyaudio in c:\\users\\mhjoy\\anaconda3\\lib\\site-packages (0.2.11)\n"
     ]
    }
   ],
   "source": [
    "! pip install pyaudio\n",
    "import speech_recognition as speech_recog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec = speech_recog.Recognizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "mic_test = speech_recog.Microphone()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Microsoft Sound Mapper - Input',\n",
       " 'Microphone (3- USB Audio Device',\n",
       " 'Microphone (HD Webcam C270)',\n",
       " 'Microphone (Realtek(R) Audio)',\n",
       " 'Microsoft Sound Mapper - Output',\n",
       " 'Speakers (3- USB Audio Device)',\n",
       " 'Realtek HD Audio 2nd output (Re',\n",
       " 'Primary Sound Capture Driver',\n",
       " 'Microphone (3- USB Audio Device)',\n",
       " 'Microphone (HD Webcam C270)',\n",
       " 'Microphone (Realtek(R) Audio)',\n",
       " 'Primary Sound Driver',\n",
       " 'Speakers (3- USB Audio Device)',\n",
       " 'Realtek HD Audio 2nd output (Realtek(R) Audio)',\n",
       " 'Realtek HD Audio 2nd output (Realtek(R) Audio)',\n",
       " 'Speakers (3- USB Audio Device)',\n",
       " 'Microphone (HD Webcam C270)',\n",
       " 'Microphone (Realtek(R) Audio)',\n",
       " 'Microphone (3- USB Audio Device)',\n",
       " 'Headphones (Realtek HD Audio 2nd output)',\n",
       " 'Line In (Realtek HD Audio Line input)',\n",
       " 'Stereo Mix (Realtek HD Audio Stereo input)',\n",
       " 'Speakers (Realtek HD Audio output)',\n",
       " 'Microphone (Realtek HD Audio Mic input)',\n",
       " 'Speakers (USB Audio Device)',\n",
       " 'Microphone (USB Audio Device)',\n",
       " 'Microphone (HD Webcam C270)']"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#getting list of available mic devices\n",
    "speech_recog.Microphone.list_microphone_names()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# speech_recog.Microphone(device_index=1) as source:\n",
    "#     rec.adjust_for_ambient_noise(source, duration=3)\n",
    "#     print(\"Reach the Microphone and say something!\")\n",
    "#     audio = rec.listen(source)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_audio():\n",
    "   r = sr.Recognizer()\n",
    "   with sr.Microphone() as source:\n",
    "      print(\"Say something!\")\n",
    "      audio = r.listen(source)\n",
    "      said = \"\"\n",
    "\n",
    "      try:\n",
    "          said = r.recognize_google(audio)\n",
    "          print(said)\n",
    "      except Exception as e:\n",
    "          print(\"Exception: \" + str(e))\n",
    "\n",
    "      return said "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Say something!\n",
      "this is CSE 499 class\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'this is CSE 499 class'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_audio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ed9e8126675b08beaed741c71341ce0253c3b1580b96516d805475f930d8ad45"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
